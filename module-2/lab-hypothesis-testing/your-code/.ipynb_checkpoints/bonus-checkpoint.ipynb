{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - T-test\n",
    "\n",
    "In statistics, t-test is used to test if two data samples have a significant difference between their means. There are two types of t-test:\n",
    "\n",
    "* **Student's t-test** (a.k.a. independent or uncorrelated t-test). This type of t-test is to compare the samples of **two independent populations** (e.g. test scores of students in two different classes). `scipy` provides the [`ttest_ind`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_ind.html) method to conduct student's t-test.\n",
    "\n",
    "* **Paired t-test** (a.k.a. dependent or correlated t-test). This type of t-test is to compare the samples of **the same population** (e.g. scores of different tests of students in the same class). `scipy` provides the [`ttest_re`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_rel.html) method to conduct paired t-test.\n",
    "\n",
    "Both types of t-tests return a number which is called the **p-value**. If p-value is below 0.05, we can confidently declare the null-hypothesis is rejected and the difference is significant. If p-value is between 0.05 and 0.1, we may also declare the null-hypothesis is rejected but we are not highly confident. If p-value is above 0.1 we do not reject the null-hypothesis.\n",
    "\n",
    "Read more about the t-test in [this article](https://researchbasics.education.uconn.edu/t-test/) and [this Quora](https://www.quora.com/What-is-the-difference-between-a-paired-and-unpaired-t-test). Make sure you understand when to use which type of t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset\n",
    "\n",
    "In this challenge we will work on the Pokemon dataset you have used last week. The goal is to test whether different groups of pokemon (e.g. Legendary vs Normal, Generation 1 vs 2, single-type vs dual-type) have different stats (e.g. HP, Attack, Defense, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>257</td>\n",
       "      <td>Blaziken</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>530</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>434</td>\n",
       "      <td>Stunky</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Dark</td>\n",
       "      <td>329</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>473</td>\n",
       "      <td>Mamoswine</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Ground</td>\n",
       "      <td>530</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>518</td>\n",
       "      <td>Musharna</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487</td>\n",
       "      <td>116</td>\n",
       "      <td>55</td>\n",
       "      <td>85</td>\n",
       "      <td>107</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #       Name   Type 1    Type 2  Total   HP  Attack  Defense  Sp. Atk  \\\n",
       "278  257   Blaziken     Fire  Fighting    530   80     120       70      110   \n",
       "482  434     Stunky   Poison      Dark    329   63      63       47       41   \n",
       "661  600      Klang    Steel       NaN    440   60      80       95       70   \n",
       "524  473  Mamoswine      Ice    Ground    530  110     130       80       70   \n",
       "577  518   Musharna  Psychic       NaN    487  116      55       85      107   \n",
       "\n",
       "     Sp. Def  Speed  Generation  Legendary  \n",
       "278       70     80           3      False  \n",
       "482       41     74           4      False  \n",
       "661       85     50           5      False  \n",
       "524       60     80           4      False  \n",
       "577       95     29           5      False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "pokemon = pd.read_csv('../../lab-df-calculation-and-transformation/your-code/Pokemon.csv')\n",
    "\n",
    "pokemon.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we want to define a function with which we can test the means of a feature set of two samples. \n",
    "\n",
    "In the next cell you'll see the annotations of the Python function that explains what this function does and its arguments and returned value. This type of annotation is called **docstring** which is a convention used among Python developers. The docstring convention allows developers to write consistent tech documentations for their codes so that others can read. It also allows some websites to automatically parse the docstrings and display user-friendly documentations.\n",
    "\n",
    "Follow the specifications of the docstring and complete the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_features(s1, s2, features=['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Total']):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for f in features:\n",
    "        \n",
    "        ttest,pval = ttest_ind(s1[f],s2[f])\n",
    "        results[f] = pval\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the `t_test_features` function, conduct t-test for Lengendary vs non-Legendary pokemons.\n",
    "\n",
    "*Hint: your output should look like below:*\n",
    "\n",
    "```\n",
    "{'HP': 1.0026911708035284e-13,\n",
    " 'Attack': 2.520372449236646e-16,\n",
    " 'Defense': 4.8269984949193316e-11,\n",
    " 'Sp. Atk': 1.5514614112239812e-21,\n",
    " 'Sp. Def': 2.2949327864052826e-15,\n",
    " 'Speed': 1.049016311882451e-18,\n",
    " 'Total': 9.357954335957446e-47}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 3.330647684846191e-15,\n",
       " 'Attack': 7.827253003205333e-24,\n",
       " 'Defense': 1.5842226094427255e-12,\n",
       " 'Sp. Atk': 6.314915770427266e-41,\n",
       " 'Sp. Def': 1.8439809580409333e-26,\n",
       " 'Speed': 2.3540754436897763e-21,\n",
       " 'Total': 3.0952457469652825e-52}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = pokemon[pokemon['Legendary']==True]\n",
    "sample_2 = pokemon[pokemon['Legendary']==False]\n",
    "t_test_features(sample_2, sample_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if pval <0.05:\n",
    "  print(\"we reject null hypothesis\")\n",
    "else:\n",
    "  print(\"we accept null hypothesis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the test results above, what conclusion can you make? Do Legendary and non-Legendary pokemons have significantly different stats on each feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We reject the hypothesis that they have the same mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, conduct t-test for Generation 1 and Generation 2 pokemons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 0.13791881412813622,\n",
       " 'Attack': 0.24050968418101457,\n",
       " 'Defense': 0.5407630349194362,\n",
       " 'Sp. Atk': 0.141197881763315,\n",
       " 'Sp. Def': 0.16781226231606386,\n",
       " 'Speed': 0.0028356954812578704,\n",
       " 'Total': 0.559914064901444}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = pokemon[pokemon['Generation']==1]\n",
    "sample_2 = pokemon[pokemon['Generation']==2]\n",
    "t_test_features(sample_2, sample_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We cannot reject the null hypothesis so we might have the same mean\n",
    "## except in speed were we can reject it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare pokemons who have single type vs those having two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 0.11060643144431853,\n",
       " 'Attack': 0.00015741395666164396,\n",
       " 'Defense': 3.250594205757004e-08,\n",
       " 'Sp. Atk': 0.0001454917404035147,\n",
       " 'Sp. Def': 0.00010893304795534396,\n",
       " 'Speed': 0.024051410794037463,\n",
       " 'Total': 1.1749035008828668e-07}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = pokemon[pokemon['Type 2'].isna()]\n",
    "sample_2 = pokemon[pokemon['Type 2'].notnull()]\n",
    "\n",
    "t_test_features(sample_2, sample_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HP cannot be rejected,\n",
    "all the other stats the null hypothesis can be rejected. \n",
    "Their means are statistically different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we want to compare whether there are significant differences of `Attack` vs `Defense`  and  `Sp. Atk` vs `Sp. Def` of all pokemons. Please write your code below.\n",
    "\n",
    "*Hint: are you comparing different populations or the same population?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07263171918634617"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = pokemon.sample(250)\n",
    "sample_2 = pokemon.sample(250)\n",
    "ttest,pval = ttest_ind(sample_1['Attack'],sample_2['Defense'])\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7055564692335065"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest,pval = ttest_ind(sample_1['Sp. Atk'],sample_2['Sp. Def'])\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#They are statistically different, the p-value is larger than alpha=.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
